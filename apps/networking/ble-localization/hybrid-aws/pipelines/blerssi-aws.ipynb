{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "!!NOTE!!\n",
    "!!User Input required!!\n",
    "\n",
    "Parameters:\n",
    "\n",
    "execution_mode (string): where the notebook is being run\n",
    "    Sample: 'local', 'in-cluster'\n",
    "\n",
    "host (string): KF Pipelines service endpoint\n",
    "    Sample:  \"http://10.10.10.10:31380/pipeline\"\n",
    "\n",
    "bucket_name (string): S3 bucket to be used by the pipeline\n",
    "    Sample: \"mxnet-model-store\"\n",
    "\n",
    "aws_secret_name (string): AWS secret where IAM creds are stored\n",
    "    Sample: 'aws-secret'\n",
    "\n",
    "role_arn (string): SageMaker Role ARN for execution of pipeline components\n",
    "    Sample: 'arn:aws:iam::${account_id}:role/service-role/AmazonSageMaker-ExecutionRole-${timestemp}'\n",
    "'''\n",
    "\n",
    "execution_mode = 'in-cluster'\n",
    "host = ''\n",
    "bucket_name = 'mxnet-model-store'\n",
    "aws_secret_name = 'aws-secret'\n",
    "role_arn = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_mode == \"local\" and host == None:\n",
    "    raise ValueError(\"Please set host to the appropriate URL\")\n",
    "elif execution_mode != \"local\":\n",
    "    execution_mode = \"in-cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "from kubernetes import client as k8s_client\n",
    "from kfp.aws import use_aws_secret\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loglevel to debug\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "model = 'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/aws/sagemaker/model/component.yaml'\n",
    "deploy = 'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/aws/sagemaker/deploy/component.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_model_op = components.load_component_from_url(model)\n",
    "sagemaker_deploy_op = components.load_component_from_url(deploy)\n",
    "\n",
    "def blerssi_mxnet_train_upload_op(step_name='mxnet-train'):\n",
    "    return dsl.ContainerOp(\n",
    "        name='mxnet-train-upload-s3',\n",
    "        image='ciscoai/mxnet-blerssi-train-upload:v0.2',\n",
    "        command=['python', '/opt/mx-dnn.py', 'train'],\n",
    "        arguments=['--bucket-name', bucket_name]\n",
    "    ).apply(use_aws_secret(secret_name=aws_secret_name, aws_access_key_id_name='AWS_ACCESS_KEY_ID', aws_secret_access_key_name='AWS_SECRET_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='MXNet Sagemaker Hybrid Pipeline',\n",
    "    description='Pipeline to train BLERSSI model using mxnet and save in aws s3 bucket'\n",
    ")\n",
    "def mxnet_pipeline(\n",
    "    region=\"\",\n",
    "    image=\"\",\n",
    "    model_name=\"\",\n",
    "    endpoint_config_name=\"\",\n",
    "    endpoint_name=\"\",\n",
    "    model_artifact_url=\"\",\n",
    "    instance_type_1=\"\",\n",
    "    role=\"\"\n",
    "):\n",
    "    train_upload_model = blerssi_mxnet_train_upload_op()\n",
    "\n",
    "    create_model = sagemaker_model_op(\n",
    "        region=region,\n",
    "        model_name=model_name,\n",
    "        image=image,\n",
    "        model_artifact_url=model_artifact_url,\n",
    "        role=role\n",
    "    ).apply(use_aws_secret(secret_name=aws_secret_name, aws_access_key_id_name='AWS_ACCESS_KEY_ID', aws_secret_access_key_name='AWS_SECRET_ACCESS_KEY'))\n",
    "    create_model.after(train_upload_model)\n",
    "\n",
    "    sagemaker_deploy_op(\n",
    "        region=region,\n",
    "        endpoint_config_name=endpoint_config_name,\n",
    "        endpoint_name=endpoint_name,\n",
    "        model_name_1=create_model.output,\n",
    "        instance_type_1=instance_type_1\n",
    "    ).apply(use_aws_secret(secret_name=aws_secret_name, aws_access_key_id_name='AWS_ACCESS_KEY_ID', aws_secret_access_key_name='AWS_SECRET_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import kfp.compiler as compiler\n",
    "    compiler.Compiler().compile(mxnet_pipeline, 'mxnet_pipeline.tar.gz')\n",
    "except RuntimeError as err:\n",
    "    logging.debug(err)\n",
    "    logging.info(\"Argo workflow failed validation check but it can still be used to run experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = None\n",
    "if execution_mode == \"local\":\n",
    "    client = kfp.Client(host=host)\n",
    "else:\n",
    "    client = kfp.Client()\n",
    "blerssi_hybrid_experiment = client.create_experiment(name='BLERSSI-Sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline\n",
    "\n",
    "Inference Image Source code: https://github.com/CiscoAI/cisco-kubeflow-starter-pack/tree/hybrid/apps/networking/ble-localization/hybrid-aws/pipelines/components/v1/mxnet-byom-inference/container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%d-%m-%y-%H-%M-%S\")\n",
    "logging.info(\"timestamp for pipeline artifacts: %s\", timestamp)\n",
    "\n",
    "# pipeline parameters :\n",
    "\n",
    "# Region where the pipeline is supposed to push/pull artifacts\n",
    "aws_region = 'us-west-2'\n",
    "\n",
    "# pre-built inference image for serving the mxnet BLERSSI model\n",
    "inference_image = '609615689023.dkr.ecr.us-west-2.amazonaws.com/mxnet-blerssi-inference:latest'\n",
    "\n",
    "# model name to create a re-usable SageMaker Model resource\n",
    "model_name = 'mxnet-blerssi-'+timestamp\n",
    "\n",
    "# endpoint config name for the SageMaker Model Serving Endpoint Config\n",
    "endpoint_config_name = 'mxnet-blerssi-endpoint-config-'+timestamp\n",
    "\n",
    "# endpoint name for SageMaker Serving Endpoint\n",
    "endpoint_name = 'mxnet-blerssi-'+timestamp\n",
    "\n",
    "# model artifact URL\n",
    "# Path to the model tarball \n",
    "model_path = 's3://'+bucket_name+'/blerssi/model.tar.gz'\n",
    "\n",
    "# AWS instance type\n",
    "instance_type = 'ml.m4.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.run_pipeline(blerssi_hybrid_experiment.id, 'blerssi-sagemaker-pipeline-'+timestamp, pipeline_package_path='mxnet_pipeline.tar.gz', params={\n",
    "    'region': aws_region,\n",
    "    'image': inference_image,\n",
    "    'model_name': model_name,\n",
    "    'endpoint_config_name': endpoint_config_name,\n",
    "    'endpoint_name': endpoint_name,\n",
    "    'model_artifact_url': model_path,\n",
    "    'instance_type_1': instance_type,\n",
    "    'role': role_arn\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation with Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from sagemaker.mxnet import MXNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "endpoint_status = 'Creating'\n",
    "\n",
    "logging.info(f\"Using endpoint: {endpoint_name}\")\n",
    "logging.info(\"Waiting for endpoint to be ready...\")\n",
    "time.sleep(120)\n",
    "\n",
    "sg_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "while endpoint_status == 'Creating':\n",
    "    resp = sg_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = resp['EndpointStatus']\n",
    "    logging.info(f\"Endpoint status: {endpoint_status}\")\n",
    "    if endpoint_status != 'Creating':\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(60)\n",
    "\n",
    "logging.info(f\"Endpoint {endpoint_name} is {endpoint_status}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer, RealTimePredictor\n",
    "\n",
    "predictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sagemaker_session, content_type= 'application/x-npy', accept= 'application/json')\n",
    "\n",
    "def _npy_dumps(data):\n",
    "    \"\"\"\n",
    "    Serialized a numpy array into a stream of npy-formatted bytes.\n",
    "    \"\"\"\n",
    "    from six import BytesIO\n",
    "    buffer = BytesIO()\n",
    "    np.save(buffer, data)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "request_data = _npy_dumps(nd.array([[-200, -200, -200, -75, -200, -200, -200, -200, -200, -200, -200, -200, -200]]).asnumpy())\n",
    "result = predictor.predict(data=request_data)\n",
    "\n",
    "import pickle\n",
    "depickled_result = pickle.loads(result)\n",
    "\n",
    "print(\"Outputs, predictions\")\n",
    "print(depickled_result[0], depickled_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Deleting endpoint...\")\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('kubeflow-fairing': conda)",
   "language": "python",
   "name": "python37564bitkubeflowfairingconda1169b2cc1734424a8ac3b433f60fa70b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
